{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy is 0.1324 \n",
      "After 1000 training step(s), validation accuracy is 0.897 \n",
      "After 2000 training step(s), validation accuracy is 0.9136 \n",
      "After 3000 training step(s), validation accuracy is 0.9232 \n",
      "After 4000 training step(s), validation accuracy is 0.9286 \n",
      "After 5000 training step(s), test accuracy is 0.9312\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# MNIST数据集相关的常数。\n",
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "# 配置神经网络的参数。\n",
    "LAYER1_NODE = 500\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.01\n",
    "TRAINING_STEPS = 5000\n",
    "\n",
    "# 定义神经网络结构\n",
    "def inference(x):\n",
    "    # 定义神经网络参数。\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    bias1 = tf.Variable(tf.constant(0.0, shape=[LAYER1_NODE]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    bias2 = tf.Variable(tf.constant(0.0, shape=[OUTPUT_NODE]))\n",
    "\n",
    "    # 计算在当前参数下神经网络前向传播的结果。\n",
    "    layer1 = tf.nn.relu(tf.matmul(x, weights1) + bias1)\n",
    "    return tf.matmul(layer1, weights2) + bias2\n",
    "\n",
    "# TensorFlow计算图创建过程。\n",
    "def define_graph():\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    y = inference(x)\n",
    "        \n",
    "    # 定义存储训练轮数的变量。 \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    # 计算交叉熵作为刻画预测值和真实值之间差距的损失函数。\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    " \n",
    "    # 使用tf.train.GradientDescentOptimizer优化算法来优化损失函数。\n",
    "    train_op=tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # 检验神经网络的正确率。\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return x, y_, train_op, accuracy\n",
    "\n",
    "# 训练模型的过程。\n",
    "def train(x, y_, train_op, accuracy, mnist):\n",
    "    # 初始化会话并开始训练过程。\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 准备验证数据。一般在神经网络的训练过程中会通过验证数据来大致判断停止的\n",
    "        # 条件和评判训练的效果。\n",
    "        validate_feed = {x: mnist.validation.images, \n",
    "                         y_: mnist.validation.labels}\n",
    "\n",
    "        # 准备测试数据。在真实的应用中，这部分数据在训练时是不可见的，这个数据只是作为  \n",
    "        # 模型优劣的最后评价标准。\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "        # 迭代地训练神经网络。\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            # 每1000轮输出一次在验证数据集上的测试结果。\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy is %g \" % (i, validate_acc))\n",
    "\n",
    "            # 产生这一轮使用的一个batch的训练数据，并运行训练过程。\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_: ys})\n",
    "            \n",
    "        # 在训练结束之后，在测试数据上检测神经网络模型的最终正确率。\n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy is %g\" % (TRAINING_STEPS, test_acc))\n",
    "\n",
    "# 主程序入口\n",
    "if __name__ == '__main__':\n",
    "    # 声明处理MNIST数据集的类，这个类在初始化时会自动下载数据。\n",
    "    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n",
    "    x, y_, train_op, accuracy = define_graph()\n",
    "    train(x, y_, train_op, accuracy, mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
